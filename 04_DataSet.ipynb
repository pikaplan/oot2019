{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_DataSet.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hNsGWfAPSkxl","colab_type":"text"},"source":["# DataSet Object\n","![UML Class Diagram](http://pantelis.me/assets/img/oot2019/UML_CD_DataSet.png)\n","\n","(*Objective: (Re-)introduce machine learning datasets and basic concepts of object oriented design, how to use custom libraries in Collab. Time: 15 mins*) "]},{"cell_type":"markdown","metadata":{"id":"Qk7FCfDAbx7k","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Qm8Cdx8mCA1l","colab_type":"text"},"source":["## Basics of machine learning datasets\n","A machine learning dataset is usually a collection of labelled samples, each one holding numerical values for features, that forms a representation vector. The collection is split to **training** and **testing** subsets, the first used during training and the second remains unknown in order to evaluate the model. If we have a large testing subset we split the collection of training samples into training and **validation** subsets, usually 90%/10%. Thus we use the smaller validation set to inspect the convergence during training."]},{"cell_type":"code","metadata":{"id":"suS5EAt4BQmT","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fX1t1zlF9Nw","colab_type":"text"},"source":["## Object oriented design\n","We will treat the dataset as an object that holds composite objects for subsets, wherein the samples and labels reside.\n","\n","### The :DataSet and :DataSubSet class relation\n","The `:DataSetCifar10` class is responsible of loading the data from the filesystem and placing them into a composite object of the `:DataSubSet` class that corresponds to training/validation/testing subset. The samples will be provided o the learning process by these instances.\n","\n","### Implementation Notes\n","*   The constructor of `:DataSetCifar10` expects a class reference that will be used to create the subset objects. In [unit tests](http://softwaretestingfundamentals.com/unit-testing/) below we provide the local declaration of `:DataSubSet`.\n","*   The `:DataSetCifar10.Load()` method ensures that the files of the dataset are downloaded and placed in the path given in the `DataSetFolder` property. The files are loaded into numpy arrays and the 5 shards are concatenated in the training subset.\n","*   The channel order of each image is transposed to R,G,B and the sample is kept in a 3D tensor with 32bit floating point values. "]},{"cell_type":"code","metadata":{"id":"2w6ZJ5ELPwWv","colab_type":"code","colab":{}},"source":["import os\n","import shutil\n","import sys\n","import zipfile\n","import tarfile\n","import pickle\n","from urllib.request import urlretrieve\n","import numpy as np\n","\n","ORIGINAL_DATASET_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/OOT2019/data/cifar10\"\n","\n","\n","# =======================================================================================================================\n","class DataSubSet(object):\n","    # --------------------------------------------------------------------------------------------------------\n","    def __init__(self):\n","        self.Samples      = None\n","        self.Labels       = None\n","        self.UIDs         = None\n","        self.SampleCount  = None\n","    # --------------------------------------------------------------------------------------------------------\n","    def AppendShard(self, p_nSamples, p_nLabels):\n","        if self.Samples is None:\n","            self.Samples = p_nSamples\n","            self.SampleCount = 0\n","        else:\n","            self.Samples = np.concatenate((self.Samples, p_nSamples), axis=0)\n","        \n","         \n","        \n","        if self.Labels is None:\n","            self.Labels = p_nLabels\n","        else:\n","            self.Labels = np.concatenate((self.Labels, p_nLabels), axis=0)\n","            \n","        nNextUIDs = np.arange(self.SampleCount, self.SampleCount + p_nSamples.shape[0],  dtype=np.int32)\n","            \n","        if self.UIDs is None:\n","          self.UIDs = nNextUIDs\n","        else:    \n","          self.UIDs = np.concatenate((self.UIDs, nNextUIDs), axis=0)\n","          \n","        self.SampleCount += p_nSamples.shape[0]\n","    # --------------------------------------------------------------------------------------------------------\n","    def GetSamples(self, p_nIndexes):\n","      \n","      nSamples = self.Samples[p_nIndexes]\n","      nLabels  = self.Labels[p_nIndexes]\n","      nUIDs    = self.UIDs[p_nIndexes]\n","      \n","      return nSamples, nLabels, nUIDs\n","    # --------------------------------------------------------------------------------------------------------\n","# =======================================================================================================================\n","\n","  \n","\n","# =======================================================================================================================\n","class DataSetCifar10(object):\n","    DOWNLOAD_URL = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    \n","    # --------------------------------------------------------------------------------------------------------\n","    def __init__(self, p_cDataSubSet=None, p_sDataFolder=ORIGINAL_DATASET_FOLDER):\n","        self.DataSubSetClass = p_cDataSubSet\n","        \n","        self.Training   = None\n","        self.Validation = None\n","        self.Testing    = None\n","        \n","        self.Samples      = None\n","        self.Labels       = None\n","        self.SampleCount  = None\n","        \n","        self.TempFolder = \"/tmp\"\n","        self.DataFolder = p_sDataFolder\n","        \n","        self.BatchesFile                = os.path.join(self.DataFolder, 'batches.meta')\n","        self.TrainingShardFileTemplate  = os.path.join(self.DataFolder, 'data_batch_%d')\n","        self.TestFileName               = os.path.join(self.DataFolder, 'test_batch')\n","        \n","        self.ClassNames = {  0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\" \n","                               , 5:\"dog\", 6: \"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\n","    # --------------------------------------------------------------------------------------------------------            \n","    def _downloadProgressCallBack(self, count, block_size, total_size):\n","        pct_complete = float(count * block_size) / total_size\n","        msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n","        sys.stdout.write(msg)\n","        sys.stdout.flush()        \n","    # --------------------------------------------------------------------------------------------------------\n","    def __ensureDataSetIsOnDisk(self):\n","        sSuffix = DataSetCifar10.DOWNLOAD_URL.split('/')[-1]\n","        sArchiveFileName = os.path.join(self.TempFolder, sSuffix)\n","        \n","        if not os.path.isfile(sArchiveFileName):\n","            sFilePath, _ = urlretrieve(url=DataSetCifar10.DOWNLOAD_URL, filename=sArchiveFileName, reporthook=self._downloadProgressCallBack)\n","            print()\n","            print(\"Download finished. Extracting files.\")\n","\n","            \n","        if sArchiveFileName.endswith(\".zip\"):\n","            zipfile.ZipFile(file=sArchiveFileName, mode=\"r\").extractall(self.TempFolder)\n","        elif sArchiveFileName.endswith((\".tar.gz\", \".tgz\")):\n","            tarfile.open(name=sArchiveFileName, mode=\"r:gz\").extractall(self.TempFolder)\n","        print(\"Done.\")\n","\n","        shutil.move(os.path.join(self.TempFolder, \"./cifar-10-batches-py\"), self.DataFolder)\n","\n","        os.remove(sArchiveFileName)\n","    # --------------------------------------------------------------------------------------------------------\n","    def _transposeImageChannels(self, p_nX, p_nShape=(32, 32, 3), p_bIsFlattening=False):\n","        nResult = np.asarray(p_nX, dtype=np.float32)\n","        nResult = nResult.reshape([-1, p_nShape[2], p_nShape[0], p_nShape[1]])\n","        nResult = nResult.transpose([0, 2, 3, 1])\n","        \n","        if p_bIsFlattening:\n","          nResult = nResult.reshape(-1, np.prod(np.asarray(p_nShape)))\n","        \n","        return nResult     \n","    # --------------------------------------------------------------------------------------------------------\n","    def Load(self):\n","        if not os.path.exists(self.DataFolder):\n","            self.__ensureDataSetIsOnDisk()\n","      \n","        self.LoadSubset(True)\n","        self.LoadSubset(False)\n","    # --------------------------------------------------------------------------------------------------------\n","    def LoadSubset(self, p_bIsTrainingSubSet=True):\n","        if p_bIsTrainingSubSet:\n","            self.Training = self.DataSubSetClass()\n","\n","            for i in range(5):\n","                with open(self.TrainingShardFileTemplate % (i+1), 'rb') as oFile:\n","                    oDict = pickle.load(oFile, encoding='latin1')\n","                    oFile.close()\n","                self.Training.AppendShard(self._transposeImageChannels(oDict[\"data\"], (32,32,3)), np.array(oDict['labels'], np.uint8))\n","        else:\n","            self.Testing = self.DataSubSetClass() \n","            \n","            with open(self.TestFileName, 'rb') as oFile:\n","                oDict = pickle.load(oFile, encoding='latin1')\n","                oFile.close()\n","            self.Testing.AppendShard(self._transposeImageChannels(oDict[\"data\"], (32,32,3)), np.array(oDict['labels'], np.uint8))\n","    # --------------------------------------------------------------------------------------------------------\n","# =======================================================================================================================\n","\n","\n","\n","\n","# --------------------------------------------------------------------------------------------------------\n","def UnitTestLoading():\n","    oDataSet = DataSetCifar10(DataSubSet)\n","    oDataSet.Load()\n","    \n","    print(\"[Training] Samples (Count,Features):%s  Labels (Count):%s\" % (oDataSet.Training.Samples.shape, oDataSet.Training.Labels.shape))\n","    print(\"[Testing ] Samples (Count,Features):%s  Labels (Count):%s\" % (oDataSet.Testing.Samples.shape , oDataSet.Testing.Labels.shape))\n","    print()\n","        \n","    import matplotlib.pyplot as plt\n","    \n","    \n","    nSamples, nLabels, nUIDs = oDataSet.Training.GetSamples([7,8,1])\n","    \n","    for nIndex, nUID in enumerate(nUIDs):\n","      print(\"Sample #%.5d Class:%s\" % (nUID, oDataSet.ClassNames[nLabels[nIndex]]))\n","      nImage =  nSamples[nIndex,...].astype(np.uint8)\n","      plt.imshow(nImage)\n","      plt.show()\n","# --------------------------------------------------------------------------------------------------------      \n","      \n","    \n","if __name__ == \"__main__\":\n","    UnitTestLoading()\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8l9GJdujfoIR","colab_type":"text"},"source":["## Decoupling the data classes\n","\n","We can decouple the two classes, by placing `:DataSetCifar10` in an external python source code file named `cifar10.py` inside common library folder named `/lib/ootf`. This will create the namespace **ootf.cifar**"]},{"cell_type":"markdown","metadata":{"id":"WohBasT0npjm","colab_type":"text"},"source":["To include `lib` into the system search path, so that python can import from there, execute the following:"]},{"cell_type":"code","metadata":{"id":"liqbtWhuhmU7","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/gdrive/My Drive/Colab Notebooks/OOT2019/lib')\n","\n","# Display the system path elements\n","for sFolder in sys.path:\n","  print(sFolder)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HV7dafdDn1ZZ","colab_type":"text"},"source":["The `ootf.cifar:DataSubSet` class is passed to the constructor of `:DataSetCifar10`"]},{"cell_type":"code","metadata":{"id":"1VQ1b19ZgQo4","colab_type":"code","colab":{}},"source":["import numpy as np\n","from ootf.cifar10 import DataSetCifar10\n","\n","\n","# =======================================================================================================================\n","class DataSubSet(object):\n","    # --------------------------------------------------------------------------------------------------------\n","    def __init__(self):\n","        self.Samples      = None\n","        self.Labels       = None\n","        self.UIDs         = None\n","        self.SampleCount  = None\n","    # --------------------------------------------------------------------------------------------------------\n","    def AppendShard(self, p_nSamples, p_nLabels):\n","        if self.Samples is None:\n","            self.Samples = p_nSamples\n","            self.SampleCount = 0\n","        else:\n","            self.Samples = np.concatenate((self.Samples, p_nSamples), axis=0)\n","        \n","         \n","        \n","        if self.Labels is None:\n","            self.Labels = p_nLabels\n","        else:\n","            self.Labels = np.concatenate((self.Labels, p_nLabels), axis=0)\n","            \n","        nNextUIDs = np.arange(self.SampleCount, self.SampleCount + p_nSamples.shape[0],  dtype=np.int32)\n","            \n","        if self.UIDs is None:\n","          self.UIDs = nNextUIDs\n","        else:    \n","          self.UIDs = np.concatenate((self.UIDs, nNextUIDs), axis=0)\n","          \n","        self.SampleCount += p_nSamples.shape[0]\n","    # --------------------------------------------------------------------------------------------------------\n","    def GetSamples(self, p_nIndexes):\n","      \n","      nSamples = self.Samples[p_nIndexes]\n","      nLabels  = self.Labels[p_nIndexes]\n","      nUIDs    = self.UIDs[p_nIndexes]\n","      \n","      return nSamples, nLabels, nUIDs\n","    # --------------------------------------------------------------------------------------------------------\n","# =======================================================================================================================\n","\n","\n","\n","# --------------------------------------------------------------------------------------------------------\n","def UnitTestLoading():\n","    oDataSet = DataSetCifar10(DataSubSet, ORIGINAL_DATASET_FOLDER)\n","    oDataSet.Load()\n","    \n","    print(\"[Training] Samples (Count,Features):%s  Labels (Count):%s\" % (oDataSet.Training.Samples.shape, oDataSet.Training.Labels.shape))\n","    print(\"[Testing ] Samples (Count,Features):%s  Labels (Count):%s\" % (oDataSet.Testing.Samples.shape , oDataSet.Testing.Labels.shape))\n","    print()\n","        \n","    import matplotlib.pyplot as plt\n","    \n","    \n","    nSamples, nLabels, nUIDs = oDataSet.Training.GetSamples([7,8,1])\n","    \n","    for nIndex, nUID in enumerate(nUIDs):\n","      print(\"Sample #%.5d Class:%s\" % (nUID, oDataSet.ClassNames[nLabels[nIndex]]))\n","      nImage =  nSamples[nIndex,...].astype(np.uint8)\n","      plt.imshow(nImage)\n","      plt.show()\n","# --------------------------------------------------------------------------------------------------------      \n","      \n","    \n","if __name__ == \"__main__\":\n","    UnitTestLoading()\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VAeYrhfCiF1h","colab_type":"text"},"source":["## An iterable subset of data\n","\n","We extend the functionality of `:DataSubSet` to implement a Python iterator that can return batches of data in a very \n","practical for loop. \n","\n","### Implementation Notes\n","*   To implement a Python iterator the `__iter__()` method should return the instance of the object and the `__next__()` method should raise a special `:StopIteration` exception to signal the end of the iteration.\n","*   There is an example property `:DataSubSet.BatchSize` illustrating how to implement getters/setters in Python."]},{"cell_type":"code","metadata":{"id":"kuXR9lYyhuam","colab_type":"code","colab":{}},"source":["import numpy as np\n","from ootf.cifar10 import DataSetCifar10\n","\n","\n","\n","\n","# =======================================================================================================================\n","class DataSubSet(object):\n","    # --------------------------------------------------------------------------------------------------------\n","    def __init__(self):\n","        self.Samples            = None\n","        self.Labels             = None\n","        self.UIDs               = None\n","        self.SampleCount        = None\n","        \n","        self.__batchSize        = None\n","        self.BatchCount         = None\n","        \n","        self.EndOfData          = True\n","        self.BatchIndex         = None\n","    # --------------------------------------------------------------------------------------------------------\n","    @property\n","    def BatchSize(self):\n","      return self.__batchSize\n","    # --------------------------------------------------------------------------------------------------------\n","    @BatchSize.setter\n","    def BatchSize(self, p_nValue):\n","      self.__batchSize = p_nValue\n","      self.BatchCount = int(self.SampleCount / self.BatchSize)\n","      if (self.SampleCount % self.BatchSize) != 0:\n","        self.BatchCount += 1\n","    # --------------------------------------------------------------------------------------------------------\n","    def AppendShard(self, p_nSamples, p_nLabels):\n","        if self.Samples is None:\n","            self.Samples = p_nSamples\n","            self.SampleCount = 0\n","        else:\n","            self.Samples = np.concatenate((self.Samples, p_nSamples), axis=0)\n","        \n","        if self.Labels is None:\n","            self.Labels = p_nLabels\n","        else:\n","            self.Labels = np.concatenate((self.Labels, p_nLabels), axis=0)\n","            \n","        nNextUIDs = np.arange(self.SampleCount, self.SampleCount + p_nSamples.shape[0],  dtype=np.int32)\n","            \n","        if self.UIDs is None:\n","          self.UIDs = nNextUIDs\n","        else:    \n","          self.UIDs = np.concatenate((self.UIDs, nNextUIDs), axis=0)\n","          \n","        self.SampleCount += p_nSamples.shape[0]\n","    # --------------------------------------------------------------------------------------------------------\n","    def GetSamples(self, p_nIndexes):\n","      \n","      nSamples = self.Samples[p_nIndexes]\n","      nLabels  = self.Labels[p_nIndexes]\n","      nUIDs    = self.UIDs[p_nIndexes]\n","      \n","      return nSamples, nLabels, nUIDs\n","    # --------------------------------------------------------------------------------------------------------\n","    def __iter__(self):\n","        assert self.__batchSize is not None, \"Batch size not specified\"\n","        \n","        self.BatchIndex = 0\n","        self.EndOfData = False      \n","        return self\n","    # --------------------------------------------------------------------------------------------------------\n","    def __next__(self):\n","        #if self.BatchIndex  < (self.BatchCount - 1):\n","        if self.BatchIndex  < self.BatchCount:\n","            nStartRange = self.BatchIndex*self.BatchSize\n","            nEndRange   = (self.BatchIndex + 1)*self.BatchSize\n","\n","            if nEndRange >= self.SampleCount:\n","                nEndRange = self.SampleCount\n","            \n","            nBatchRange     = np.arange(nStartRange, nEndRange, dtype=int)\n","            nBatchSamples   = self.Samples[nBatchRange,...]\n","            nBatchLabels    = self.Labels[nBatchRange,...]\n","            nBatchUIDs      = self.UIDs[nBatchRange]\n","            \n","            self.BatchIndex  += 1\n","            self.EndOfData = (self.BatchIndex == self.BatchCount)\n","            \n","            return nBatchRange, nBatchSamples, nBatchLabels, nBatchUIDs\n","        else:\n","            raise StopIteration()        \n","    # --------------------------------------------------------------------------------------------------------\n","# =======================================================================================================================\n","\n","\n","\n","\n","# --------------------------------------------------------------------------------------------------------\n","def UnitTestIteration():\n","    import matplotlib.pyplot as plt\n","    \n","    oDataSet = DataSetCifar10(DataSubSet, ORIGINAL_DATASET_FOLDER)\n","    oDataSet.Load()\n","    oDataSet.Training.BatchSize = 8192\n","    \n","    print(\"[Training] Batches :%d\" % (oDataSet.Training.BatchCount))\n","    print()\n","\n","    \n","    \n","    nStepIndex = 1\n","    nEpochNumber = 1\n","    while nEpochNumber < 4: \n","      print(\"Epoch:%d\" % nEpochNumber)\n","      for nBatchRange, nBatchSamples, nBatchLabels, nBatchUIDs in oDataSet.Training:\n","        print(\"Step #%.3d | Range:[%.5d - %.5d]\" % (nStepIndex, nBatchRange[0], nBatchRange[-1]), \"Samples:%s Labels:%s UIDs:%s\" % (nBatchSamples.shape, nBatchLabels.shape, nBatchUIDs.shape))\n","        # Show the horse\n","        if 7 in nBatchUIDs:\n","          nImage =  nBatchSamples[np.where(nBatchUIDs==7)][0,...].astype(np.uint8)\n","          print(nImage.shape)\n","          plt.imshow(nImage)\n","          plt.show()\n","      \n","        nStepIndex += 1\n","      nEpochNumber += 1\n","      \n","# --------------------------------------------------------------------------------------------------------      \n","      \n","    \n","if __name__ == \"__main__\":\n","    UnitTestIteration()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFASzEirqQvO","colab_type":"text"},"source":["The `:DataSubSet` class is added to the **oot.base** namespace of our framework. "]},{"cell_type":"code","metadata":{"id":"nuwgZS-KqRMv","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/gdrive/My Drive/Colab Notebooks/OOT2019/lib')\n","\n","import matplotlib.pyplot as plt\n","from ootf.base import DataSubSet\n","from ootf.cifar10 import DataSetCifar10\n","\n","\n","oDataSet = DataSetCifar10(DataSubSet, ORIGINAL_DATASET_FOLDER)\n","oDataSet.Load()\n","oDataSet.Training.BatchSize = 8192\n","\n","\n","nStepIndex = 1\n","nEpochNumber = 1\n","while nEpochNumber < 4: \n","  print(\"Epoch:%d\" % nEpochNumber)\n","  for nBatchRange, nBatchSamples, nBatchLabels, nBatchUIDs in oDataSet.Training:\n","    print(\"Step #%.3d | Range:[%.5d - %.5d]\" % (nStepIndex, nBatchRange[0], nBatchRange[-1]), \"Samples:%s Labels:%s UIDs:%s\" % (nBatchSamples.shape, nBatchLabels.shape, nBatchUIDs.shape))\n","    # Show the boat\n","    if 8 in nBatchUIDs:\n","      nImage =  nBatchSamples[np.where(nBatchUIDs==8)][0,...].astype(np.uint8)\n","      print(nImage.shape)\n","      plt.imshow(nImage)\n","      plt.show()    \n","    nStepIndex += 1\n","  nEpochNumber += 1"],"execution_count":0,"outputs":[]}]}