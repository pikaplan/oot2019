{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_DownloadCIFAR10.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XSTd9SR9V47f","colab_type":"text"},"source":["# Get Some Data\n","(*Objective: Download CIFAR10 into Google Drive, convert it to TFRecords. Time: 5 mins*) "]},{"cell_type":"markdown","metadata":{"id":"egGFDPU1RegB","colab_type":"text"},"source":["## The CIFAR10 dataset\n","\n","We will use the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset that contains 32x32 RGB images. It is used for proof of concept testing in several machine learning methods and also to evaluate of CNN image classifiers. \n","\n","<img src=\"https://miro.medium.com/max/824/1*SZnidBt7CQ4Xqcag6rd8Ew.png\" width=\"700\" border=\"1\"/>\n","\n","The current value of accuracy metric for this dataset has reached 99%. You can find the leaderboard in [paperswithcode.com](https://paperswithcode.com/sota/image-classification-on-cifar-10) a great site that hosts papers and links to their corresponding source code.\n","\n","We start by mounting Google Drive in this runtime"]},{"cell_type":"code","metadata":{"id":"3CGAShjqRaEL","colab_type":"code","outputId":"35a44968-aa20-49f0-87f6-16633cf663db","executionInfo":{"status":"ok","timestamp":1566774186216,"user_tz":-180,"elapsed":25966,"user":{"displayName":"Pantelis I. Kaplanoglou","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8ij8NrZ3YXO-BjI4za4ZmyoTDWpuofvuv9Ec1=s64","userId":"00705661083529504289"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_SkTb53dRiVL","colab_type":"text"},"source":["## Downloading from URL\n","The `:DataSetCifar10Downloader` is a class that checks the existence of CIFAR10 files and if needed downloads the dataset from [Alex Krizhevsky's](https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/) page. It extracts the archive and copies them in the `data/cifar10` subfolder of your tutorial workspace. "]},{"cell_type":"code","metadata":{"id":"kOuVCsYNRidz","colab_type":"code","colab":{}},"source":["import os\n","import shutil\n","import sys\n","import zipfile\n","import tarfile\n","import pickle\n","from urllib.request import urlretrieve\n","import numpy as np\n","\n","ORIGINAL_DATASET_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/OOT2019/data/cifar10\"\n","TFRECORDS_DATASET_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/OOT2019/data/tfcifar10\"\n","\n","\n","# =======================================================================================================================\n","class DataSetCifar10Downloader(object):\n","    DOWNLOAD_URL = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    \n","    # --------------------------------------------------------------------------------------------------------\n","    def __init__(self, p_sDataFolder):\n","        self.TempFolder = \"/tmp\"\n","        self.DataFolder = p_sDataFolder\n","    # --------------------------------------------------------------------------------------------------------            \n","    def _downloadProgressCallBack(self, count, block_size, total_size):\n","        pct_complete = float(count * block_size) / total_size\n","        msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n","        sys.stdout.write(msg)\n","        sys.stdout.flush()        \n","    # --------------------------------------------------------------------------------------------------------\n","    def __ensureDataSetIsOnDisk(self):\n","        sSuffix = DataSetCifar10.DOWNLOAD_URL.split('/')[-1]\n","        sArchiveFileName = os.path.join(self.TempFolder, sSuffix)\n","        \n","        if not os.path.isfile(sArchiveFileName):\n","            sFilePath, _ = urlretrieve(url=DataSetCifar10.DOWNLOAD_URL, filename=sArchiveFileName, reporthook=self._downloadProgressCallBack)\n","            print()\n","            print(\"Download finished. Extracting files.\")\n","\n","            \n","        if sArchiveFileName.endswith(\".zip\"):\n","            zipfile.ZipFile(file=sArchiveFileName, mode=\"r\").extractall(self.TempFolder)\n","        elif sArchiveFileName.endswith((\".tar.gz\", \".tgz\")):\n","            tarfile.open(name=sArchiveFileName, mode=\"r:gz\").extractall(self.TempFolder)\n","        print(\"Done.\")\n","\n","        shutil.move(os.path.join(self.TempFolder, \"./cifar-10-batches-py\"), self.DataFolder)\n","\n","        os.remove(sArchiveFileName)\n","    # --------------------------------------------------------------------------------------------------------\n","    def Download(self):\n","        if not os.path.exists(self.DataFolder):\n","            self.__ensureDataSetIsOnDisk()\n","    # --------------------------------------------------------------------------------------------------------\n","# =======================================================================================================================\n","\n","\n","oDataSet = DataSetCifar10(ORIGINAL_DATASET_FOLDER)\n","oDataSet.Download()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNIAROV-R760","colab_type":"text"},"source":["## Converting to TFRecords format\n","\n","We are going to convert the images into the TFRecord format and store the pixel mean and standard deviation for later use."]},{"cell_type":"code","metadata":{"id":"l6KTqbqER8D8","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow as tf\n","import joblib\n","\n","# --------------------------------------------------------------------------------------------------------\n","def convert_to_tfdataset(p_sSourceDataFolder, p_sDestDataFolder):\n","    # --------------------------------------------------------------------------------------------------------\n","    def _int64_feature(value):\n","        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","    # --------------------------------------------------------------------------------------------------------\n","    def _bytes_feature(value):\n","        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","    # --------------------------------------------------------------------------------------------------------\n","    def save_to_records(p_sFileName, p_nImages, p_nLabels, p_sSubsetName):\n","        print(\"[>] Converting %s subset\" % p_sSubsetName)\n","        writer = tf.python_io.TFRecordWriter(p_sFileName)\n","        for i in range(p_nImages.shape[0]):\n","            image_raw = p_nImages[i].tostring()\n","            example = tf.train.Example(features=tf.train.Features(feature={\n","                'height'    : _int64_feature(32),\n","                'width'     : _int64_feature(32),\n","                'depth'     : _int64_feature(3),\n","                'label'     : _int64_feature(int(p_nLabels[i])),\n","                'image_raw' : _bytes_feature(image_raw)\n","                }))\n","            writer.write(example.SerializeToString())\n","            if ((i+1) % 5000) == 0:\n","              print(\" |__ Written %d tfrecords\" % (i+1))\n","    # --------------------------------------------------------------------------------------------------------        \n","    if not os.path.exists(p_sDestDataFolder):\n","      os.makedirs(p_sDestDataFolder)\n","    \n","    # train set\n","    train_images = np.zeros((50000,3072), dtype=np.uint8)\n","    trian_labels = np.zeros((50000,), dtype=np.int32)\n","    for i in range(5):\n","        sFileName = os.path.join(p_sSourceDataFolder, 'data_batch_%d' % (i+1))\n","        with open(sFileName, 'rb') as oFile:\n","                data_batch = pickle.load(oFile, encoding='latin1')\n","\n","        train_images[10000*i:10000*(i+1)] = data_batch['data']\n","        trian_labels[10000*i:10000*(i+1)] = np.asarray(data_batch['labels'], dtype=np.int32)\n","    train_images = np.reshape(train_images, [50000,3,32,32])\n","    train_images = np.transpose(train_images, axes=[0,2,3,1]) # NCHW -> NHWC\n","    save_to_records(os.path.join(p_sDestDataFolder, \"train.tf\"), train_images, trian_labels, \"training\")\n","\n","    # mean and std\n","    print(\"[>] Calculating and storing pixel mean and std values\")\n","    image_mean = np.mean(train_images.astype(np.float32), axis=(0,1,2))\n","    image_std = np.std(train_images.astype(np.float32), axis=(0,1,2))\n","    joblib.dump({'mean': image_mean, 'std': image_std}, os.path.join(p_sDestDataFolder, \"meanstd.pkl\"), compress=5)\n","\n","    # test set\n","    sFileName = os.path.join(p_sSourceDataFolder, 'test_batch')\n","    with open(sFileName, 'rb') as oFile:\n","        data_batch = pickle.load(oFile, encoding='latin1')\n","    \n","    \n","    test_images = data_batch['data']\n","    test_images = np.reshape(test_images, [10000,3,32,32])\n","    test_images = np.transpose(test_images, axes=[0,2,3,1])\n","    test_labels = np.asarray(data_batch['labels'], dtype=np.int32)\n","    save_to_records(os.path.join(p_sDestDataFolder, \"test.tf\"), test_images, test_labels, \"testing\")\n","# --------------------------------------------------------------------------------------------------------\n","\n","convert_to_tfdataset(ORIGINAL_DATASET_FOLDER, TFRECORDS_DATASET_FOLDER)"],"execution_count":0,"outputs":[]}]}