{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_Tensorboard.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AvOaFq4rszmA","colab_type":"text"},"source":["# Visualizing Graph of Computations with Tensorboard\n","\n","A very usefull part of the Tensorflow framework is the Tensorboard web application that is a visualization helper. Amongst others, it helps the researcher to inspect the computational graph and monitor the training process through graphs.\n","\n","\n","\n","(*Objective: Use Tensorboard in Colab, familiarize computational graph/scopes and implement a basic neural network. Time: 12 mins*) \n"]},{"cell_type":"markdown","metadata":{"id":"Nt-PX6VKELTT","colab_type":"text"},"source":["## Installing in Google Collab\n","\n","In Google collab we can install libraries and Python packages in the virtual environment. \n","\n","We are going to need the [ngrok](https://ngrok.com/) library to expose our virtual localhost to a public URL"]},{"cell_type":"code","metadata":{"id":"GPiFcmeAEGpX","colab_type":"code","colab":{}},"source":["! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yO6G756NhSJn","colab_type":"text"},"source":["Below there is an example of Python package installation. The Colab runtime has most common packages preinstalled."]},{"cell_type":"code","metadata":{"id":"DcISGHj9LEBM","colab_type":"code","colab":{}},"source":["! pip install xlwt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3QZPF9-KX1G","colab_type":"text"},"source":["## Multilayer Perceptron (MLP) Neural Network \n","<img src=\"https://miro.medium.com/max/958/1*QVIyc5HnGDWTNX3m-nIm9w.png\" width=\"300\" border=\"1\"/>\n","\n","The source code creates the computational graph for a simple Multi-Layer Perceptron (MLP) neural network. It has an input vector with 3072 dimensions, 1024 neurons in the hidden layer and 10 neurons in the output layer. The graph is exported to a Tensorboard log file.\n","\n"]},{"cell_type":"code","metadata":{"id":"8JsVNVWgA6M6","colab_type":"code","colab":{}},"source":["# NEURAL NETWORK - Spaghetti Code\n","\n","import tensorflow as tf\n","import math\n","\n","TENSORBOARD_FOLDER = \"/tmp/tboard\"\n","\n","oGraph = tf.Graph()\n","with oGraph.as_default():\n","  \n","  # ........ Input Layer .......\n","  tInput = tf.placeholder(tf.uint8, shape=(100,3072))\n","  tInputNormalized = tf.cast(tInput, tf.float32) / tf.constant(255.0, tf.float32)\n","  tX = tInputNormalized\n","  \n","  # ........ Hidden Layer (128 Neurons) .......\n","  tWeight1      = tf.Variable(tf.random.truncated_normal([3072,1024], stddev=math.sqrt(2/(3072+1024))), tf.float32)\n","  tBias1        = tf.Variable(tf.zeros(1024), tf.float32)\n","  tSynapticSum1 = tf.matmul(tX, tWeight1) + tBias1\n","  # Hidden layer has the sigmoid activation function\n","  tActivation1  = tf.nn.sigmoid(tSynapticSum1)\n","  \n","  # ........ Output Layer .......\n","  tWeight2      = tf.Variable(tf.random.truncated_normal([1024,10], stddev=math.sqrt(2/(1024+10))), tf.float32)\n","  tBias2        = tf.Variable(tf.zeros(10), tf.float32)\n","  tSynapticSum2 = tf.matmul(tActivation1, tWeight2) + tBias2\n","  # Output layer has the sigmoid activation function\n","  tActivation2  = tf.nn.sigmoid(tSynapticSum2)\n","  \n","  \n","  with tf.Session() as oSession:\n","    assert oSession.graph == oGraph, \"The current session is using the default graph\"\n","    oSession.run(tf.initializers.global_variables())\n","  \n","  \n","    oWriter = tf.summary.FileWriter(TENSORBOARD_FOLDER, graph=oSession.graph, flush_secs=20)\n","    oWriter.flush()\n","    \n","    print(\"Graph exported to %s\" % TENSORBOARD_FOLDER)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LhtzarDHEMV6","colab_type":"text"},"source":["## Tensorboard\n","\n","We start tensorboard and tunneling using ngrok. The output of tensorboard becomes available at the returned URL.\n","\n"]},{"cell_type":"code","metadata":{"id":"SpKvGde2ENVS","colab_type":"code","colab":{}},"source":["# kill all running ngrok instances\n","!pkill -f ngrok\n","!pkill -f tensorboard\n","\n","# Execute tensorboard\n","LOG_DIR = '/tmp/tboard/'\n","get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(TENSORBOARD_FOLDER))\n","\n","# execute ngrok\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","# Do the tunneling\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hHFBEPzeFNrq","colab_type":"text"},"source":["## Contextual organization with variable scopes\n","\n","Inspecting the graph of the first example, we notice that the model parameters (variables) are automatically named and that the tree lacks a contextual organization. The code is rewritten bellow, using variable scopes and custom variable names. "]},{"cell_type":"code","metadata":{"id":"k9v23KgMKwuD","colab_type":"code","colab":{}},"source":["# NEURAL NETWORK - Spaghetti Code with Scopes\n","\n","import tensorflow as tf\n","import math\n","\n","TENSORBOARD_FOLDER = \"/tmp/tboard2\"\n","\n","oGraph = tf.Graph()\n","with oGraph.as_default():\n","  with tf.variable_scope(\"NeuralNet\"):\n","    with tf.variable_scope(\"Input\"):\n","      tInput = tf.placeholder(tf.uint8, shape=(100,3072))\n","      tInputNormalized = tf.cast(tInput, tf.float32) / tf.constant(255.0, tf.float32)\n","      tX = tInputNormalized\n","      \n","    with tf.variable_scope(\"FC1\"):\n","      tWeight1      = tf.get_variable(\"w\", shape=[3072,1024], initializer=tf.initializers.truncated_normal(mean=0.0, stddev=math.sqrt(2/(3072+1024))), dtype=tf.float32)\n","      tBias1        = tf.get_variable(\"b\", shape=[1024], initializer=tf.initializers.constant(0.0, dtype=tf.float32))\n","      tSynapticSum1 = tf.matmul(tX, tWeight1) + tBias1\n","      # Hidden layer has the sigmoid activation function\n","      tActivation1  = tf.nn.sigmoid(tSynapticSum1)\n","  \n","\n","    with tf.variable_scope(\"FC2\"):\n","      # ........ Output Layer .......\n","      tWeight2      = tf.get_variable(\"w\", shape=[1024,10], initializer=tf.initializers.truncated_normal(mean=0.0, stddev=math.sqrt(2/(1024+10))), dtype=tf.float32)\n","      tBias2        = tf.get_variable(\"b\", shape=[10], initializer=tf.initializers.constant(0.0), dtype=tf.float32)\n","      tSynapticSum2 = tf.matmul(tActivation1, tWeight2) + tBias2\n","      # Output layer has the sigmoid activation function\n","      tActivation2  = tf.nn.sigmoid(tSynapticSum2)\n","  \n","  \n","  with tf.Session() as oSession:\n","    assert oSession.graph == oGraph, \"The current session is using the default graph\"\n","    oSession.run(tf.initializers.global_variables())\n","  \n","  \n","    oWriter = tf.summary.FileWriter(TENSORBOARD_FOLDER, graph=oSession.graph, flush_secs=20)\n","    oWriter.flush()\n","    \n","    print(\"Graph exported to %s\" % TENSORBOARD_FOLDER)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_3N1PxjPvgKF","colab_type":"text"},"source":["Restarting tensorboard will display a contextually organized graph. Notice how the model parameters are named."]},{"cell_type":"code","metadata":{"id":"8VvY-3R7ubZR","colab_type":"code","colab":{}},"source":["# kill all running ngrok instances\n","!pkill -f ngrok\n","!pkill -f tensorboard\n","\n","# Execute tensorboard\n","LOG_DIR = '/tmp/tboard2/'\n","get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(TENSORBOARD_FOLDER))\n","\n","# execute ngrok\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","# Do the tunneling\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]}]}